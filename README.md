 ğŸ¤– RAG Chatbot with Gemini + LangChain

This project is a **Retrieval-Augmented Generation (RAG)** chatbot built using **LangChain** and **Google's Gemini API**. It takes PDF documents as input, creates vector embeddings using HuggingFace, stores them in a FAISS vector database, and uses a Large Language Model to answer user queries based on the document content.

---

 ğŸ“ Project Structure
 rag-chatbot/
â”‚
â”œâ”€â”€ chatbot/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ app.py # Main chatbot script
â”‚ â”œâ”€â”€ loader.py # Loads and splits PDF files
â”‚ â”œâ”€â”€ embedder.py # Embedding generation and vector store logic
â”‚ â”œâ”€â”€ gemini_llm.py # Gemini API wrapper
â”‚ â””â”€â”€ rag_chain.py # Chain configuration for retrieval-based QA
â”‚
â”œâ”€â”€ data/ # Folder for PDF documents
â”œâ”€â”€ vectorstore/ # Folder where FAISS index is saved
â”œâ”€â”€ venv/ # Python virtual environment (excluded in Git)
â”œâ”€â”€ .env # Environment variables (API key, paths, etc.)
â”œâ”€â”€ .gitignore # Git ignore rules
â””â”€â”€ requirements.txt # Python dependencies



  Setup Instructions

 1. Clone the Repository

git clone https://github.com/areeba42197/rag-chatbot.git
cd rag-chatbot

2. Install Dependencies

pip install -r requirements.txt

3. Add PDF Documents

4. Run the Chatbot
python -m chatbot.app








 ğŸ¤– RAG Chatbot with Gemini + LangChain

This project is a **Retrieval-Augmented Generation (RAG)** chatbot built using **LangChain** and **Google's Gemini API**. It takes PDF documents as input, creates vector embeddings using HuggingFace, stores them in a FAISS vector database, and uses a Large Language Model to answer user queries based on the document content.

---

 ğŸ“ Project Structure
 rag-chatbot/
â”‚
â”œâ”€â”€ chatbot/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ app.py 
â”‚ â”œâ”€â”€ loader.py 
â”‚ â”œâ”€â”€ embedder.py 
â”‚ â”œâ”€â”€ gemini_llm.py
â”‚ â””â”€â”€ rag_chain.py 
â”‚
â”œâ”€â”€ data/ 
â”œâ”€â”€ vectorstore/ 
â”œâ”€â”€ venv/ 
â”œâ”€â”€ .env # Environment variables 
â”œâ”€â”€ .gitignore
â””â”€â”€ requirements.txt



  **Setup Instructions**

 1. Clone the Repository

git clone https://github.com/areeba42197/rag-chatbot.git
cd rag-chatbot

2. Install Dependencies

pip install -r requirements.txt

3. Add PDF Documents

4. Run the Chatbot
python -m chatbot.app







